{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pneumothorax_classification_maxaccuracy.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLv4xG_-nEju",
        "colab_type": "code",
        "outputId": "ddbb8503-1ddb-4844-dbe1-ca9fade054eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "!pip install pydicom\n",
        "# !pip install pretrainedmodels"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/d5/da1fdf3b967e324ee47a7ad9553c9b94c1193b6b98afd9eeda0efb76b9f7/pydicom-1.3.0-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-1.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGmP-Y6bwZrk",
        "colab_type": "code",
        "outputId": "47127a6f-61b3-4efd-9201-0d2200c9996f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import glob\n",
        "import pydicom\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from torch import Tensor\n",
        "from __future__ import print_function, division\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "###\n",
        "from __future__ import print_function, division\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "#import SimpleITK as sitk\n",
        "from torch import optim\n",
        "import torch.utils.data\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import natsort\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchsummary\n",
        "#from torch.utils.tensorboard import SummaryWriter\n",
        "#from tensorboardX import SummaryWriter\n",
        "import cv2\n",
        "import shutil\n",
        "import random\n",
        "import time\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJhD_lN6KGID",
        "colab_type": "text"
      },
      "source": [
        "#Data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObyrT9hynzdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_dcm_info(dataset):\n",
        "    print(\"Filename.........:\", file_path)\n",
        "    print(\"Storage type.....:\", dataset.SOPClassUID)\n",
        "    print()\n",
        "\n",
        "    pat_name = dataset.PatientName\n",
        "    display_name = pat_name.family_name + \", \" + pat_name.given_name\n",
        "    print(\"Patient's name......:\", display_name)\n",
        "    print(\"Patient id..........:\", dataset.PatientID)\n",
        "    print(\"Patient's Age.......:\", dataset.PatientAge)\n",
        "    print(\"Patient's Sex.......:\", dataset.PatientSex)\n",
        "    print(\"Modality............:\", dataset.Modality)\n",
        "    print(\"Body Part Examined..:\", dataset.BodyPartExamined)\n",
        "    print(\"View Position.......:\", dataset.ViewPosition)\n",
        "    \n",
        "    if 'PixelData' in dataset:\n",
        "        rows = int(dataset.Rows)\n",
        "        cols = int(dataset.Columns)\n",
        "        print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n",
        "            rows=rows, cols=cols, size=len(dataset.PixelData)))\n",
        "        if 'PixelSpacing' in dataset:\n",
        "            print(\"Pixel spacing....:\", dataset.PixelSpacing)\n",
        "\n",
        "def plot_pixel_array(dataset, figsize=(10,10)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2JHyACDpG8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i= 0 \n",
        "for file_path in glob.glob(\"/content/drive/My Drive/CMPUT 617(PROJECT)/project/new train/*.dcm\"):\n",
        "    i=i+1\n",
        "    dataset = pydicom.dcmread(file_path)\n",
        "    show_dcm_info(dataset)\n",
        "    plot_pixel_array(dataset)\n",
        "    if(i==1):\n",
        "      break # Comment this out to see all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "smMDY2yD6lWB",
        "colab": {}
      },
      "source": [
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "##decoding the mask and specify it in the image\n",
        "def mask2rle(img, width, height):\n",
        "    rle = []\n",
        "    lastColor = 0;\n",
        "    currentPixel = 0;\n",
        "    runStart = -1;\n",
        "    runLength = 0;\n",
        "\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            currentColor = img[x][y]\n",
        "            if currentColor != lastColor:\n",
        "                if currentColor == 255:\n",
        "                    runStart = currentPixel;\n",
        "                    runLength = 1;\n",
        "                else:\n",
        "                    rle.append(str(runStart));\n",
        "                    rle.append(str(runLength));\n",
        "                    runStart = -1;\n",
        "                    runLength = 0;\n",
        "                    currentPixel = 0;\n",
        "            elif runStart > -1:\n",
        "                runLength += 1\n",
        "            lastColor = currentColor;\n",
        "            currentPixel+=1;\n",
        "\n",
        "    return \" \".join(rle)\n",
        "\n",
        "def rle2mask(rle, width, height):\n",
        "    mask= np.zeros(width* height)\n",
        "    array = np.asarray([int(x) for x in rle.split()])\n",
        "    starts = array[0::2]\n",
        "    lengths = array[1::2]\n",
        "    current_position = 0\n",
        "    if(lengths.shape[0]>1):\n",
        "        for index, start in enumerate(starts):\n",
        "            current_position += start\n",
        "            mask[current_position:current_position+lengths[index]] = 255\n",
        "            current_position += lengths[index]\n",
        "\n",
        "    return mask.reshape(width, height)\n",
        "\n",
        "\n",
        "# #################################################\n",
        "#################################################    \n",
        "# start = 1   # Starting index of images\n",
        "# num_img = 20 # Total number of images to show\n",
        "\n",
        "\n",
        "# df = pd.read_csv('/content/drive/My Drive/CMPUT 617(PROJECT)/project/train-rle.csv', header=None, index_col=0)\n",
        "\n",
        "# fig, ax = plt.subplots(nrows=1, ncols=num_img, sharey=True, figsize=(num_img*10,10))\n",
        "# for q, file_path in enumerate(glob.glob('/content/drive/My Drive/CMPUT 617(PROJECT)/project/new train/*.dcm')[start:start+num_img]):\n",
        "#     dataset = pydicom.dcmread(file_path)\n",
        "#     #print(file_path.split('/')[-1][:-4])\n",
        "#     # ax[q].imshow(dataset.pixel_array, cmap=plt.cm.bone)before\n",
        "#     ax[q].imshow(clahe.apply(dataset.pixel_array), cmap=plt.cm.bone)\n",
        "    \n",
        "#     # print(len(df.loc[file_path.split('/')[-1][:-4],1]))\n",
        "#     # if df.loc[file_path.split('/')[-1][:-4],1] != '-1':\n",
        "#     if len(df.loc[file_path.split('/')[-1][:-4],1]) > 4 :\n",
        "#         mask = rle2mask(df.loc[file_path.split('/')[-1][:-4],1], 1024, 1024).T\n",
        "#         ax[q].set_title('See Marker')\n",
        "#         ax[q].imshow(mask, alpha=0.3, cmap=\"Reds\")\n",
        "#     else:\n",
        "#         ax[q].set_title('Nothing to see')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7WETa18nBN6",
        "colab_type": "code",
        "outputId": "1a1727c8-9775-455e-8732-796299b630a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "train_glob = '/content/drive/My Drive/CMPUT 617(PROJECT)/project/new train/*.dcm'\n",
        "train_fns = sorted(glob.glob(train_glob))[0:2000]\n",
        "df_full = pd.read_csv('/content/drive/My Drive/CMPUT 617(PROJECT)/project/train-rle.csv', index_col='ImageId')\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "#######################################################\n",
        "#Passing the Dataset of Images and Labels\n",
        "#######################################################\n",
        "im_height = 1024\n",
        "im_width = 1024\n",
        "im_chan = 1\n",
        "# Get train images and masks\n",
        "X1_train = np.zeros((len(train_fns), im_height, im_width, im_chan), dtype=np.uint8)\n",
        "X_train = np.zeros((len(train_fns), im_height, im_width, im_chan), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_fns), im_height, im_width, 1), dtype=np.bool)\n",
        "print('Getting train images and masks ... ')\n",
        "sys.stdout.flush()\n",
        "for n, _id in tqdm(enumerate(train_fns), total=len(train_fns)):\n",
        "    dataset1 = pydicom.read_file(_id)\n",
        "    dataset  = clahe.apply(dataset1.pixel_array)\n",
        "    X_train[n] = np.expand_dims(dataset, axis=2)\n",
        "    try:\n",
        "        if '-1' in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n",
        "            Y_train[n] = np.zeros((1024, 1024, 1))\n",
        "        else:\n",
        "            if type(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']) == str:\n",
        "                Y_train[n] = np.expand_dims(rle2mask(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels'], 1024, 1024), axis=2)\n",
        "            else:\n",
        "                Y_train[n] = np.zeros((1024, 1024, 1))\n",
        "                for x in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n",
        "                    Y_train[n] =  Y_train[n] + np.expand_dims(rle2mask(x, 1024, 1024), axis=2)\n",
        "    except KeyError:\n",
        "        print(f\"Key {_id.split('/')[-1][:-4]} without mask, assuming healthy patient.\")\n",
        "        Y_train[n] = np.zeros((1024, 1024, 1)) # Assume missing masks are empty masks.\n",
        "\n",
        "print('Done!')\n",
        "np.save('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_train_big', X_train)\n",
        "np.save('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_train_big', Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting train images and masks ... \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 253/2000 [01:38<10:04,  2.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.10231.1517875222.737143 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|█▉        | 397/2000 [02:38<08:31,  3.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.10362.1517875223.377845 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 446/2000 [02:56<08:51,  2.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.10407.1517875223.567351 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 655/2000 [04:12<08:24,  2.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.10599.1517875224.488727 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 744/2000 [04:46<06:34,  3.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.1068.1517875166.144255 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 1209/2000 [07:45<04:22,  3.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.11104.1517875231.169401 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 66%|██████▋   | 1329/2000 [08:33<03:57,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.11215.1517875231.757436 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 1704/2000 [10:53<01:44,  2.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.11557.1517875233.601090 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 1714/2000 [10:57<01:45,  2.70it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.11566.1517875233.640521 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86%|████████▋ | 1726/2000 [11:01<01:52,  2.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.11577.1517875233.694347 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 1734/2000 [11:04<01:37,  2.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.11584.1517875233.731531 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [12:43<00:00,  3.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR5T3YWoUhdt",
        "colab_type": "text"
      },
      "source": [
        "#BALANCING THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEHV2Ugeq92T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "3be68552-6259-432c-b9ad-29d08512d7e0"
      },
      "source": [
        "im_height = 128\n",
        "im_width = 128\n",
        "im_chan = 1\n",
        "###26% positive\n",
        "X_train_1 = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_train_big.npy')\n",
        "Y_train_1 = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_train_big.npy')\n",
        "X_valid = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_valid_big.npy')\n",
        "Y_valid = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_valid_big.npy')\n",
        "X_test = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_test_big.npy')\n",
        "Y_test = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_test_big.npy')\n",
        "\n",
        "\n",
        "j=0\n",
        "for i in range (0,len(Y_test)):\n",
        "  if( np.count_nonzero(Y_test[i][:][:][:]) > 1 ):\n",
        "      j =j+1\n",
        "\n",
        "print(j,\"test\")\n",
        "\n",
        "kk=0\n",
        "for i in range (0,len(Y_train_1)):\n",
        "  if( np.count_nonzero(Y_train_1[i][:][:][:]) > 1 ):\n",
        "      kk =kk+1\n",
        "      \n",
        "print(kk,\"train\")\n",
        "\n",
        "##################\n",
        "\n",
        "X_train_2 = np.zeros((400,1024,1024,1))\n",
        "Y_train_2= np.zeros((400,1024,1024,1)) \n",
        "# X_test_2 = np.zeros((k,1024,1024,1))\n",
        "# Y_test_2 = np.zeros((k,1024,1024,1))\n",
        "\n",
        "\n",
        "\n",
        "k=-1\n",
        "\n",
        "for i in range (0,len(X_train_1)):\n",
        "  if( np.count_nonzero(Y_train_1[i][:][:][:]) > 1 ):\n",
        "      k=k+1\n",
        "      X_train_2[k][:][:][:]= X_train_1[i][:][:][:] \n",
        "      Y_train_2[k][:][:][:]= Y_train_1[i][:][:][:] \n",
        "      if(k==200):\n",
        "         break\n",
        "\n",
        "p = k \n",
        "for i in range (0,len(X_train_1)):\n",
        "  if( np.count_nonzero(Y_train_1[i][:][:][:]) == 0 ):\n",
        "      X_train_2[p+1][:][:][:]= X_train_1[i][:][:][:] \n",
        "      Y_train_2[p+1][:][:][:]= Y_train_1[i][:][:][:] \n",
        "      p=p+1\n",
        "      if( p == 399 ):\n",
        "          break\n",
        "# h=0\n",
        "# for i in range (0,len(Y_train_2)):\n",
        "#   if( np.count_nonzero(Y_train_2[i][:][:][:]) > 1 ):\n",
        "#       h =h+1\n",
        "print(Y_train_2.squeeze(3).shape)\n",
        "np.save('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_train_balanced', X_train_2)\n",
        "np.save('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_train_balanced', Y_train_2)\n",
        "####################################\n",
        "\n",
        "# # labels_train = np.zeros((len(X_train),1))\n",
        "# labels_train = -np.ones((len(X_train),1))\n",
        "# for i in range (0,len(X_train)):\n",
        "#   if( np.count_nonzero(Y_train[i][:][:][:]) > 1 ):\n",
        "#       labels_train[i] = 1\n",
        "# labels_train_NEW =  np.repeat(labels_train, 64, axis=0)\n",
        "\n",
        "# # labels_valid = np.zeros((len(X_valid),1))\n",
        "# labels_valid = -np.ones((len(X_valid),1))\n",
        "# for i in range (0,len(X_valid)):\n",
        "#   if( np.count_nonzero(Y_valid[i][:][:][:]) > 1 ):\n",
        "#       labels_valid[i] = 1      \n",
        "# labels_valid_NEW =  np.repeat(labels_valid, 64, axis=0)\n",
        "\n",
        "# labels_test = np.zeros((len(X_test),1))\n",
        "# for i in range (0,len(X_test)):\n",
        "#   if( np.count_nonzero(Y_test[i][:][:][:]) > 1 ):\n",
        "#       labels_test[i] = 1\n",
        "# labels_test_NEW =  np.repeat(labels_test, 64, axis=0)\n",
        "\n",
        "# ##################################\n",
        "\n",
        "# X_train = X_train.reshape((-1, im_height, im_width, 1))\n",
        "# Y_train = Y_train.reshape((-1, im_height, im_width, 1))\n",
        "# X_valid = X_valid.reshape((-1, im_height, im_width, 1))\n",
        "# Y_valid = Y_valid.reshape((-1, im_height, im_width, 1))\n",
        "# X_test = X_test.reshape((-1, im_height, im_width, 1))\n",
        "# Y_test = Y_test.reshape((-1, im_height, im_width, 1))\n",
        "\n",
        "\n",
        "# X_train = np.transpose(X_train, (0,3,2,1))\n",
        "# Y_train =np.transpose(Y_train , (0,3,2,1))\n",
        "# X_valid =np.transpose(X_valid, (0,3,2,1))\n",
        "# Y_valid= np.transpose(Y_valid, (0,3,2,1))\n",
        "# X_test =np.transpose(X_test, (0,3,2,1))\n",
        "# Y_test= np.transpose(Y_test, (0,3,2,1))\n",
        "\n",
        "# X_train  = np.repeat(X_train, 3, axis=1)\n",
        "# X_valid  = np.repeat(X_valid, 3, axis=1)\n",
        "# X_test  = np.repeat(X_test, 3, axis=1)\n",
        "\n",
        "# dataset = TensorDataset( Tensor(X_train), Tensor(labels_train_NEW) )\n",
        "# dataset2 =  TensorDataset( Tensor(X_valid), Tensor(labels_valid_NEW))\n",
        "# dataset3 =  TensorDataset( Tensor(X_test), Tensor(labels_test_NEW))\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "# valid_loader = torch.utils.data.DataLoader(dataset2, batch_size=32, shuffle=True)\n",
        "# test_loader =  torch.utils.data.DataLoader(dataset3, batch_size=1, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25 test\n",
            "464 train\n",
            "(400, 1024, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXItgEQCUAbv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_train_balanced.npy')\n",
        "Y_train = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_train_balanced.npy')\n",
        "X_valid = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_valid_big.npy')\n",
        "Y_valid = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_valid_big.npy')\n",
        "X_test = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_test_big.npy')\n",
        "Y_test = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_test_big.npy')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# labels_train = np.zeros((len(X_train),1))\n",
        "\n",
        "labels_train = -np.ones((len(X_train),1))\n",
        "for i in range (0,len(X_train)):\n",
        "  if( np.count_nonzero(Y_train[i][:][:][:]) > 1 ):\n",
        "      labels_train[i] = 1\n",
        "labels_train_NEW =  np.repeat(labels_train, 16, axis=0)\n",
        "\n",
        "# labels_valid = np.zeros((len(X_valid),1))\n",
        "labels_valid = -np.ones((len(X_valid),1))\n",
        "for i in range (0,len(X_valid)):\n",
        "  if( np.count_nonzero(Y_valid[i][:][:][:]) > 1 ):\n",
        "      labels_valid[i] = 1      \n",
        "labels_valid_NEW =  np.repeat(labels_valid, 16, axis=0)\n",
        "\n",
        "# labels_test = np.zeros((len(X_test),1))\n",
        "labels_test = -np.ones((len(X_test),1))\n",
        "for i in range (0,len(X_test)):\n",
        "  if( np.count_nonzero(Y_test[i][:][:][:]) > 1 ):\n",
        "      labels_test[i] = 1\n",
        "labels_test_NEW =  np.repeat(labels_test, 16, axis=0)\n",
        "\n",
        "##################################\n",
        "im_height = 256\n",
        "im_width = 256\n",
        "\n",
        "X_train = X_train.reshape((-1, im_height, im_width, 1))\n",
        "Y_train = Y_train.reshape((-1, im_height, im_width, 1))\n",
        "X_valid = X_valid.reshape((-1, im_height, im_width, 1))\n",
        "Y_valid = Y_valid.reshape((-1, im_height, im_width, 1))\n",
        "X_test = X_test.reshape((-1, im_height, im_width, 1))\n",
        "Y_test = Y_test.reshape((-1, im_height, im_width, 1))\n",
        "\n",
        "\n",
        "X_train = np.transpose(X_train, (0,3,2,1))\n",
        "Y_train =np.transpose(Y_train , (0,3,2,1))\n",
        "X_valid =np.transpose(X_valid, (0,3,2,1))\n",
        "Y_valid= np.transpose(Y_valid, (0,3,2,1))\n",
        "X_test =np.transpose(X_test, (0,3,2,1))\n",
        "Y_test= np.transpose(Y_test, (0,3,2,1))\n",
        "\n",
        "X_train  = np.repeat(X_train, 3, axis=1)\n",
        "X_valid  = np.repeat(X_valid, 3, axis=1)\n",
        "X_test  = np.repeat(X_test, 3, axis=1)\n",
        "\n",
        "dataset = TensorDataset( Tensor(X_train), Tensor(labels_train_NEW) )\n",
        "dataset2 =  TensorDataset( Tensor(X_valid), Tensor(labels_valid_NEW))\n",
        "dataset3 =  TensorDataset( Tensor(X_test), Tensor(labels_test_NEW))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset2, batch_size=32, shuffle=True)\n",
        "test_loader =  torch.utils.data.DataLoader(dataset3, batch_size=1, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17eV_CjXOeG4",
        "colab_type": "text"
      },
      "source": [
        "#classification task( having Pneumothorax or not )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPSxl1IUOcMo",
        "colab_type": "code",
        "outputId": "5d18826d-cff0-4254-cf98-946b17718bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "# import pretrainedmodels\n",
        "model = models.densenet121(pretrained='imagenet')\n",
        "# model = pretrainedmodels.se_resnext50_32x4d(pretrained='imagenet')\n",
        "# model = models.resnet18(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 72.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAKynSoTVXRa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9087c5b6-b5e4-4274-c08a-6c6af248b907"
      },
      "source": [
        "\n",
        "\n",
        "# classifier_input = model.classifier.in_features\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma):\n",
        "        super().__init__()\n",
        "        self.gamma =  gamma\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if not (target.size() == input.size()):\n",
        "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
        "                             .format(target.size(), input.size()))\n",
        "        max_val = (-input).clamp(min=0)\n",
        "        loss = input - input * target + max_val + \\\n",
        "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
        "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
        "        loss = (invprobs * self.gamma).exp() * loss\n",
        "        return loss.mean()\n",
        "\n",
        "def svm_l2loss(a, y, weight, C=1, batch_fraction=1000):\n",
        "    \"\"\"\n",
        "    Calculate SVM-L2 loss:\n",
        "    l(w) = 0.5 * w^T w + C \\sum_{i=1}^N max(1 - w^Tx_n y_n, 0)^2\n",
        "    Parameters:\n",
        "        a: torch.Tensor --- activation from previous layer, i.e. a = w^T x\n",
        "        y: torch.Tensor --- vector of labels\n",
        "        weight: torch.Tensor --- weight tensor of previous layer\n",
        "        C: float --- regularization constant\n",
        "        batch_fraction: float --- fraction of samples in mini-batch (compared to the whole sample)\n",
        "    \"\"\"\n",
        "    relu = F.relu(1 - a * y)**2\n",
        "    #0.5 * batch_fraction * (weight * weight).sum()\n",
        "    return   relu.sum() \n",
        "\n",
        "\n",
        "class SVM(nn.Module):\n",
        "    \"\"\"\n",
        "    Linear Support Vector Machine\n",
        "    -----------------------------\n",
        "    This SVM is a subclass of the PyTorch nn module that\n",
        "    implements the Linear  function. The  size  of  each \n",
        "    input sample is 2 and output sample  is 1.\n",
        "    \"\"\"\n",
        "    def __init__(self,in_features):\n",
        "        super().__init__()  # Call the init function of nn.Module\n",
        "        self.in_features = in_features\n",
        "        self.fully_connected = nn.Linear(in_features,1)  # Implement the Linear function\n",
        "        self.weight = ( nn.Parameter(torch.FloatTensor(in_features, 1)))\n",
        "        self.weight.data.uniform_()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        fwd = self.fully_connected(x)  # Forward pass\n",
        "        return fwd\n",
        "num_labels = 2\n",
        "# classifier = nn.Sequential(nn.Linear(classifier_input, 512),\n",
        "#                            nn.ReLU(),\n",
        "#                            nn.Linear(512, 256),\n",
        "#                            nn.ReLU(),\n",
        "#                            KernelLayer(256, n_features, kernel_type, self.gamma)\n",
        "#                            )\n",
        "                           \n",
        "\n",
        "classifier = nn.Sequential(nn.Dropout(),\n",
        "                                nn.Linear(classifier_input,4*1024),\n",
        "                                nn.ReLU(True),\n",
        "                                nn.Dropout(),\n",
        "                                nn.Linear(4*1024,4*512),\n",
        "                                nn.ReLU(True),\n",
        "                                SVM(4*512)\n",
        "                                # nn.Linear(512,1)\n",
        "                                )\n",
        "\n",
        "model.classifier = classifier  \n",
        "###############\n",
        "weights = [1, 1.5]\n",
        "class_weights=torch.FloatTensor(weights).cuda()\n",
        "\n",
        "# Set the error function using torch.nn as nn library\n",
        "criterion = nn.NLLLoss()\n",
        "criterion2 = FocalLoss(2)\n",
        "# Set the optimizer function using torch.optim as optim library\n",
        "params = list(model.classifier.parameters())  \n",
        "optimizer = torch.optim.Adam(params,lr=0.0001)\n",
        "# optimizer = torch.optim.SGD(params, lr=0.1, momentum=0.9)\n",
        "##############set up the gpu\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Move model to the device specified above\n",
        "epochs = 80\n",
        "model.to(device)\n",
        "train_final = np.zeros(epochs)\n",
        "valid_final = np.zeros(epochs)\n",
        "accuracy_final = np.zeros(epochs)\n",
        "#########\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    last_module = list(model.modules())[-1]\n",
        "    train_loss = 0\n",
        "    val_loss = 0\n",
        "    accuracy_train = 0\n",
        "    accuracy_valid = 0\n",
        "    # Training the model\n",
        "    model.train()\n",
        "    counter = 0\n",
        "    for input1, labels in train_loader:\n",
        "        inputs = input1\n",
        "        # Move to  \n",
        "        inputs  = inputs.to(device).float()\n",
        "        labels1  = labels.type(torch.LongTensor).to(device)\n",
        "        # Clear optimizers\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        output = model.forward(inputs)\n",
        "        # print(labels)\n",
        "        # output = torch.exp(output)\n",
        "        # # Loss\n",
        "        # loss1 = criterion(output, labels1.squeeze(1))\n",
        "        # loss2 = criterion2(top_p.squeeze(), labels1.squeeze(1))\n",
        "        loss3 = svm_l2loss(output.cuda() , labels1.cuda() , last_module.weight, C=1 , batch_fraction=1000)\n",
        "        # print(loss3 )\n",
        "        # print(loss3,'.12f')\n",
        "        # Calculate gradients (backpropogation)\n",
        "        # print(labels1)\n",
        "        # print(\"salam\")\n",
        "        loss3.backward()\n",
        "        # Adjust parameters based on gradients\n",
        "        optimizer.step()\n",
        "        # Add the loss to the training set's rnning loss\n",
        "        # top_p, top_class = output.topk(1, dim=1)\n",
        "        # equals = top_class == labels.view(*top_class.shape).cuda()\n",
        "        # equals = output_2 == labels.view(*top_class.shape).cuda()\n",
        "        equals =  torch.sign(output) == labels1\n",
        "        train_loss += loss3.item()*inputs.size(0)\n",
        "        accuracy_train += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "    # Print the progress of our training\n",
        "        counter += 1\n",
        "        # print(counter, \"/\", len(train_loader))\n",
        "        \n",
        "    # Evaluating the model\n",
        "    model.eval()\n",
        "    counter = 0\n",
        "    # Tell torch not to calculate gradients\n",
        "    with torch.no_grad():\n",
        "        for input1, labels in valid_loader:\n",
        "            inputs = input1\n",
        "            inputs  = inputs.to(device)\n",
        "            labels  = labels.to(device)\n",
        "            # Move to device1\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # Forward pass\n",
        "            labels1  = labels.type(torch.LongTensor).to(device)\n",
        "            output = model.forward(inputs)\n",
        "            # Calculate Loss\n",
        "            # output = torch.exp(output)\n",
        "            # top_p, top_class = output_2.topk(1, dim=1)\n",
        "            # # Loss\n",
        "            # loss1 = criterion(output, labels1.squeeze(1))\n",
        "            # loss2 = criterion2(top_p.squeeze(), labels1.squeeze(1))\n",
        "            loss3 = svm_l2loss(output.cuda(), labels1.cuda() , last_module.weight, C=0.1 , batch_fraction=1000)\n",
        "            # Get the top class of the output\n",
        "            # top_p, top_class = output.topk(1, dim=1)\n",
        "            # See how many of the classes were correct?\n",
        "            # equals = top_class  == labels.view(*top_class.shape)\n",
        "            equals = output.sign() == labels1\n",
        "            # Calculate the mean (get the accuracy for this batch)\n",
        "            accuracy_valid += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "            val_loss += loss3.item()*inputs.size(0)\n",
        "            # Print the progress of our evaluation\n",
        "            counter += 1\n",
        "            # print(counter, \"/\", len(valid_loader))\n",
        "\n",
        "########################################################################### \n",
        "         \n",
        "###########################################################################\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = val_loss/len(valid_loader.dataset)\n",
        "    train_final[epoch] =(train_loss)\n",
        "    valid_final[epoch] = (valid_loss)\n",
        "    accuracy_final[epoch] =accuracy_train/len(train_loader) \n",
        "    # Print out the information\n",
        "    print('Accuracy: ', accuracy_valid/len(valid_loader))\n",
        "    print('Accuracy: ', accuracy_train/len(train_loader))\n",
        "    if((accuracy_valid/len(valid_loader))>0.75):\n",
        "       break\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
        "torch.save(model,'/content/drive/My Drive/CMPUT 617(PROJECT)/project/MODEL_CLASSIFICATION.pt')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.63375\n",
            "Accuracy:  0.54078125\n",
            "Epoch: 0 \tTraining Loss: 32.955526 \tValidation Loss: 29.820489\n",
            "Accuracy:  0.383125\n",
            "Accuracy:  0.56296875\n",
            "Epoch: 1 \tTraining Loss: 31.333026 \tValidation Loss: 35.022529\n",
            "Accuracy:  0.443125\n",
            "Accuracy:  0.57421875\n",
            "Epoch: 2 \tTraining Loss: 31.204189 \tValidation Loss: 32.794513\n",
            "Accuracy:  0.583125\n",
            "Accuracy:  0.575625\n",
            "Epoch: 3 \tTraining Loss: 31.035366 \tValidation Loss: 30.464460\n",
            "Accuracy:  0.613125\n",
            "Accuracy:  0.58609375\n",
            "Epoch: 4 \tTraining Loss: 30.744050 \tValidation Loss: 29.689514\n",
            "Accuracy:  0.5825\n",
            "Accuracy:  0.5803125\n",
            "Epoch: 5 \tTraining Loss: 30.930603 \tValidation Loss: 30.438296\n",
            "Accuracy:  0.47875\n",
            "Accuracy:  0.5809375\n",
            "Epoch: 6 \tTraining Loss: 30.907393 \tValidation Loss: 32.096388\n",
            "Accuracy:  0.455\n",
            "Accuracy:  0.58390625\n",
            "Epoch: 7 \tTraining Loss: 30.557331 \tValidation Loss: 33.554046\n",
            "Accuracy:  0.735\n",
            "Accuracy:  0.58296875\n",
            "Epoch: 8 \tTraining Loss: 30.666631 \tValidation Loss: 27.797502\n",
            "Accuracy:  0.701875\n",
            "Accuracy:  0.58828125\n",
            "Epoch: 9 \tTraining Loss: 30.552661 \tValidation Loss: 28.722355\n",
            "Accuracy:  0.640625\n",
            "Accuracy:  0.5865625\n",
            "Epoch: 10 \tTraining Loss: 30.530427 \tValidation Loss: 29.746070\n",
            "Accuracy:  0.635625\n",
            "Accuracy:  0.59296875\n",
            "Epoch: 11 \tTraining Loss: 30.352308 \tValidation Loss: 29.662294\n",
            "Accuracy:  0.53125\n",
            "Accuracy:  0.58875\n",
            "Epoch: 12 \tTraining Loss: 30.451764 \tValidation Loss: 31.240243\n",
            "Accuracy:  0.635\n",
            "Accuracy:  0.5934375\n",
            "Epoch: 13 \tTraining Loss: 30.349292 \tValidation Loss: 30.040533\n",
            "Accuracy:  0.7575\n",
            "Accuracy:  0.59296875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DenseNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _DenseBlock. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _DenseLayer. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type _Transition. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type AvgPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type SVM. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq1QCDAhxHQQ",
        "colab_type": "code",
        "outputId": "161a087c-cf6b-4aff-c7d9-3a64bd5813da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model = models.densenet121(pretrained='imagenet')\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model = torch.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/MODEL_CLASSIFICATION.pt')\n",
        "# classifier_input = model.classifier.in_features\n",
        "num_labels = 2\n",
        "classifier = nn.Sequential(nn.Linear(classifier_input, 1024),\n",
        "                           nn.ReLU(),\n",
        "                           nn.Linear(1024, 512),\n",
        "                           nn.ReLU(),\n",
        "                           nn.Linear(512, num_labels),\n",
        "                           nn.LogSoftmax(dim=1))\n",
        "# Replace default classifier with new classifier\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model_X.classifier = classifier\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "def predict(image, model):\n",
        "    counter = 0 \n",
        "    # Tell torch not to calculate gradients\n",
        "    accuracy_test = 0\n",
        "    with torch.no_grad():\n",
        "        for input1, labels in image:\n",
        "            inputs = input1\n",
        "            inputs  = inputs.to(device)\n",
        "            labels  = labels.to(device)\n",
        "            # Move to device\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # Forward pass\n",
        "            labels1  = labels.type(torch.LongTensor).to(device)\n",
        "            output = model.forward(inputs)\n",
        "            # Calculate Loss\n",
        "            # Since our model outputs a LogSoftmax, find the real \n",
        "            # percentages by reversing the log function\n",
        "            # output = torch.exp(output)\n",
        "            # Get the top class of the output\n",
        "            # top_p, top_class = output.topk(1, dim=1)\n",
        "            # See how many of the classes were correct?\n",
        "            equals = output.sign() == labels1\n",
        "            # Calculate the mean (get the accuracy for this batch)\n",
        "            accuracy_test += equals.type(torch.FloatTensor).item()\n",
        "            # Print the progress of our evaluation\n",
        "            counter += 1\n",
        "            # print(counter, \"/\", len(valid_loader))\n",
        "    test_accuracy = accuracy_test/len(image)\n",
        "    print(test_accuracy)\n",
        "    print(len(image))\n",
        "top_prob = predict(test_loader, model)\n",
        "\n",
        "# Show the image\n",
        "# show_image(image)\n",
        "# Print the results\n",
        "#print(\"The model is \", top_prob*100, \"% certain that the image has a predicted class of 1 \"  )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.73875\n",
            "1600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aCSbiUXS3yI",
        "colab_type": "text"
      },
      "source": [
        "#classification task2 new"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ky5Pa1JTGBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ################################\n",
        "# #classifier_input = model.classifier.in_features\n",
        "# num_labels = 2\n",
        "# classifier = nn.Sequential(nn.Linear(classifier_input, 1024),\n",
        "#                            nn.ReLU(),\n",
        "#                            nn.Linear(1024, 512),\n",
        "#                            nn.ReLU(),\n",
        "#                            nn.Linear(512, num_labels),\n",
        "#                            nn.LogSoftmax(dim=1))\n",
        "# # Replace default classifier with new classifier\n",
        "# model.classifier = classifier\n",
        "\n",
        "# ###############\n",
        "# weights = [1, 1.5]\n",
        "# class_weights=torch.FloatTensor(weights).cuda()\n",
        "\n",
        "# # Set the error function using torch.nn as nn library\n",
        "# criterion = nn.NLLLoss(class_weights)\n",
        "# # Set the optimizer function using torch.optim as optim library\n",
        "# optimizer = torch.optim.Adam(model.classifier.parameters(),lr=0.001)\n",
        "\n",
        "# ##############set up the gpu\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# # Move model to the device specified above\n",
        "# model.to(device)\n",
        "\n",
        "# #########\n",
        "# epochs = 100\n",
        "# for epoch in range(epochs):\n",
        "#     train_loss = 0\n",
        "#     val_loss = 0\n",
        "#     accuracy_train = 0\n",
        "#     accuracy_valid = 0\n",
        "#     # Training the model\n",
        "#     model.train()\n",
        "#     counter = 0\n",
        "#     for input1, labels in train_loader:\n",
        "#         inputs = input1\n",
        "#         # Move to  \n",
        "#         inputs  = inputs.to(device).float()\n",
        "#         labels1  = labels.type(torch.LongTensor).to(device)\n",
        "#         # Clear optimizers\n",
        "#         optimizer.zero_grad()\n",
        "#         # Forward pass\n",
        "#         output = model.forward(inputs)\n",
        "#         # Loss\n",
        "#         loss = criterion(output, labels1.squeeze(1))\n",
        "#         # Calculate gradients (backpropogation)\n",
        "#         loss.backward()\n",
        "#         # Adjust parameters based on gradients\n",
        "#         optimizer.step()\n",
        "#         # Add the loss to the training set's rnning loss\n",
        "#         top_p, top_class = output.topk(1, dim=1)\n",
        "#         equals = top_class == labels.view(*top_class.shape).cuda()\n",
        "#         train_loss += loss.item()*inputs.size(0)\n",
        "#         accuracy_train += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "#     # Print the progress of our training\n",
        "#         counter += 1\n",
        "#         # print(counter, \"/\", len(train_loader))\n",
        "        \n",
        "#     # Evaluating the model\n",
        "#     model.eval()\n",
        "#     counter = 0\n",
        "#     # Tell torch not to calculate gradients\n",
        "#     with torch.no_grad():\n",
        "#         for input1, labels in valid_loader:\n",
        "#             inputs = input1\n",
        "#             inputs  = inputs.to(device)\n",
        "#             labels  = labels.to(device)\n",
        "#             # Move to device\n",
        "#             inputs, labels = inputs.to(device), labels.to(device)\n",
        "#             # Forward pass\n",
        "#             labels1  = labels.type(torch.LongTensor).to(device)\n",
        "#             output = model.forward(inputs)\n",
        "#             # Calculate Loss\n",
        "#             valloss = criterion(output,labels1.squeeze(1))\n",
        "#             # Add loss to the validation set's running loss\n",
        "#             ##jash injas\n",
        "#             val_loss += valloss.item()*inputs.size(0)\n",
        "#             # Since our model outputs a LogSoftmax, find the real \n",
        "#             # percentages by reversing the log function\n",
        "#             output = torch.exp(output)\n",
        "#             # Get the top class of the output\n",
        "#             top_p, top_class = output.topk(1, dim=1)\n",
        "#             # See how many of the classes were correct?\n",
        "#             equals = top_class == labels.view(*top_class.shape)\n",
        "#             # Calculate the mean (get the accuracy for this batch)\n",
        "#             accuracy_valid += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "#             # Print the progress of our evaluation\n",
        "#             counter += 1\n",
        "#             # print(counter, \"/\", len(valid_loader))\n",
        "\n",
        "# ###########################################################################\n",
        "#     train_loss = train_loss/len(train_loader.dataset)\n",
        "#     valid_loss = val_loss/len(valid_loader.dataset)\n",
        "#     # Print out the information\n",
        "#     print('Accuracy: ', accuracy_valid/len(valid_loader))\n",
        "#     print('Accuracy: ', accuracy_train/len(train_loader))\n",
        "#     print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
        "# torch.save(model,'/content/drive/My Drive/CMPUT 617(PROJECT)/project/MODEL_CLASSIFICATION_2.pt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VU1OhqZVZkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # classifier_input = model.classifier.in_features\n",
        "# num_labels = 2\n",
        "# classifier = nn.Sequential(nn.Linear(classifier_input, 1024),\n",
        "#                            nn.ReLU(),\n",
        "#                            nn.Linear(1024, 512),\n",
        "#                            nn.ReLU(),\n",
        "#                            nn.Linear(512, num_labels),\n",
        "#                            nn.LogSoftmax(dim=1))\n",
        "# # Replace default classifier with new classifier\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.classifier = classifier\n",
        "# model_X = torch.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/MODEL_CLASSIFICATION.pt')\n",
        "# model_X.classifier = classifier\n",
        "# model_X.to(device)\n",
        "# model.eval()\n",
        "\n",
        "# def predict(image, model):\n",
        "#     # Pass the image through our model\n",
        "#     probs = 0\n",
        "#     classes = 0\n",
        "#     j=0\n",
        "#     k=0\n",
        "#     for input1, labels in image: \n",
        "#         inputs = input1\n",
        "#         inputs  = inputs.to(device)\n",
        "#         labels  = labels.to(device)\n",
        "#         # Move to device\n",
        "#         inputs, labels = inputs.to(device), labels.to(device)\n",
        "#         # Forward pass\n",
        "#         labels1  = labels.type(torch.LongTensor).to(device)\n",
        "#         output = model.forward(inputs)\n",
        "#         j = j+1\n",
        "#         classes = output.topk(1, dim=1)[1]\n",
        "#         if(classes==0):\n",
        "#            probs1 =output.topk(1, dim=1)[0]\n",
        "#         if(classes==1):\n",
        "#            probs1 = 1-output.topk(1, dim=1)[0]\n",
        "#         probs = probs + probs1\n",
        "#         if(j==64):\n",
        "#            if((probs.item()/64)>0.5):\n",
        "#               prob_asli = 1\n",
        "#            if((probs.item()/64)<0.5):    \n",
        "#               prob_asli = 0\n",
        "#            if(prob_asli == labels):\n",
        "#               k=k+1\n",
        "#            probs = 0\n",
        "#            classes = 0\n",
        "#            j=0\n",
        "#     print(k/100)    \n",
        "\n",
        "# top_prob = predict(test_loader, model_X)\n",
        "# # Show the image\n",
        "# # show_image(image)\n",
        "# # Print the results\n",
        "# #print(\"The model is \", top_prob*100, \"% certain that the image has a predicted class of 1 \"  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2scMw37QVdzl",
        "colab_type": "text"
      },
      "source": [
        "#finished"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VhQELTdzLkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def calc_loss(prediction, target, bce_weight=0.5):\n",
        "#     \"\"\"Calculating the loss and metrics\n",
        "#     Args:\n",
        "#         prediction = predicted image\n",
        "#         target = Targeted image\n",
        "#         metrics = Metrics printed\n",
        "#         bce_weight = 0.5 (default)\n",
        "#     Output:\n",
        "#         loss : dice loss of the epoch \"\"\"\n",
        "#     bce = F.binary_cross_entropy_with_logits(prediction, target)\n",
        "#     prediction = F.sigmoid(prediction)\n",
        "#     dice = dice_loss(prediction, target)\n",
        "\n",
        "#     loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "\n",
        "#     return loss\n",
        "# ##########\n",
        "# def dice_loss(prediction, target):\n",
        "#     \"\"\"Calculating the dice loss\n",
        "#     Args:\n",
        "#         prediction = predicted image\n",
        "#         target = Targeted image\n",
        "#     Output:\n",
        "#         dice_loss\"\"\"\n",
        "\n",
        "#     smooth = 1.0\n",
        "\n",
        "#     i_flat = prediction.view(-1)\n",
        "#     t_flat = target.view(-1)\n",
        "\n",
        "#     intersection = (i_flat * t_flat).sum()\n",
        "\n",
        "#     return 1 - ((2. * intersection + smooth) / (i_flat.sum() + t_flat.sum() + smooth))\n",
        "\n",
        "# #########################################\n",
        "\n",
        "# def dice_coeff(im1, im2, empty_score=1.0):\n",
        "#     \"\"\"Calculates the dice coefficient for the images\"\"\"\n",
        "\n",
        "#     im1 = np.asarray(im1).astype(np.bool)\n",
        "#     im2 = np.asarray(im2).astype(np.bool)\n",
        "\n",
        "#     if im1.shape != im2.shape:\n",
        "#         raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
        "\n",
        "#     im1 = im1 > 0.5\n",
        "#     im2 = im2 > 0.5\n",
        "\n",
        "#     im_sum = im1.sum() + im2.sum()\n",
        "#     if im_sum == 0:\n",
        "#         return empty_score\n",
        "\n",
        "#     # Compute Dice coefficient\n",
        "#     intersection = np.logical_and(im1, im2)\n",
        "#     #print(im_sum)\n",
        "\n",
        "#     return 2. * intersection.sum() / im_sum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOXItlZ7yuI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class conv_block(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Convolution Block \n",
        "#     \"\"\"\n",
        "#     def __init__(self, in_ch, out_ch):\n",
        "#         super(conv_block, self).__init__()\n",
        "        \n",
        "#         self.conv = nn.Sequential(\n",
        "#             nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "#             nn.BatchNorm2d(out_ch),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "#             nn.BatchNorm2d(out_ch),\n",
        "#             nn.ReLU(inplace=True))\n",
        "\n",
        "#     def forward(self, x):\n",
        "\n",
        "#         x = self.conv(x)\n",
        "#         return x\n",
        "\n",
        "# ###############################\n",
        "# class up_conv(nn.Module):\n",
        "#     \"\"\"\n",
        "#     Up Convolution Block\n",
        "#     \"\"\"\n",
        "#     def __init__(self, in_ch, out_ch):\n",
        "#         super(up_conv, self).__init__()\n",
        "#         self.up = nn.Sequential(\n",
        "#             nn.Upsample(scale_factor=2),\n",
        "#             nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "#             nn.BatchNorm2d(out_ch),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.up(x)\n",
        "#         return x\n",
        "# ####################################\n",
        "# class U_Net(nn.Module):\n",
        "#     \"\"\"\n",
        "#     UNet - Basic Implementation\n",
        "#     Paper : https://arxiv.org/abs/1505.04597\n",
        "#     \"\"\"\n",
        "#     def __init__(self, in_ch=1, out_ch=1):\n",
        "#         super(U_Net, self).__init__()\n",
        "\n",
        "#         n1 = 64\n",
        "#         filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
        "        \n",
        "#         self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "#         self.Conv1 = conv_block(in_ch, filters[0])\n",
        "#         self.Conv2 = conv_block(filters[0], filters[1])\n",
        "#         self.Conv3 = conv_block(filters[1], filters[2])\n",
        "#         self.Conv4 = conv_block(filters[2], filters[3])\n",
        "#         self.Conv5 = conv_block(filters[3], filters[4])\n",
        "\n",
        "#         self.Up5 = up_conv(filters[4], filters[3])\n",
        "#         self.Up_conv5 = conv_block(filters[4], filters[3])\n",
        "\n",
        "#         self.Up4 = up_conv(filters[3], filters[2])\n",
        "#         self.Up_conv4 = conv_block(filters[3], filters[2])\n",
        "\n",
        "#         self.Up3 = up_conv(filters[2], filters[1])\n",
        "#         self.Up_conv3 = conv_block(filters[2], filters[1])\n",
        "\n",
        "#         self.Up2 = up_conv(filters[1], filters[0])\n",
        "#         self.Up_conv2 = conv_block(filters[1], filters[0])\n",
        "\n",
        "#         self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "#        # self.active = torch.nn.Sigmoid()\n",
        "\n",
        "#     def forward(self, x):\n",
        "\n",
        "#         e1 = self.Conv1(x)\n",
        "\n",
        "#         e2 = self.Maxpool1(e1)\n",
        "#         e2 = self.Conv2(e2)\n",
        "\n",
        "#         e3 = self.Maxpool2(e2)\n",
        "#         e3 = self.Conv3(e3)\n",
        "\n",
        "#         e4 = self.Maxpool3(e3)\n",
        "#         e4 = self.Conv4(e4)\n",
        "\n",
        "#         e5 = self.Maxpool4(e4)\n",
        "#         e5 = self.Conv5(e5)\n",
        "\n",
        "#         d5 = self.Up5(e5)\n",
        "#         d5 = torch.cat((e4, d5), dim=1)\n",
        "\n",
        "#         d5 = self.Up_conv5(d5)\n",
        "\n",
        "#         d4 = self.Up4(d5)\n",
        "#         d4 = torch.cat((e3, d4), dim=1)\n",
        "#         d4 = self.Up_conv4(d4)\n",
        "\n",
        "#         d3 = self.Up3(d4)\n",
        "#         d3 = torch.cat((e2, d3), dim=1)\n",
        "#         d3 = self.Up_conv3(d3)\n",
        "\n",
        "#         d2 = self.Up2(d3)\n",
        "#         d2 = torch.cat((e1, d2), dim=1)\n",
        "#         d2 = self.Up_conv2(d2)\n",
        "\n",
        "#         out = self.Conv(d2)\n",
        "\n",
        "#         # d1 = self.active(out)\n",
        "#         #F.softmax(out,dim=3)\n",
        "#         return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FvvoYQY1PYg",
        "colab_type": "code",
        "outputId": "28544d63-7f90-4ce5-d82f-e6437e690d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "# if not train_on_gpu:\n",
        "#     print('CUDA is not available. Training on CPU')\n",
        "# else:\n",
        "#     print('CUDA is available. Training on GPU')\n",
        "\n",
        "# device = torch.device(\"cuda:0\" if train_on_gpu else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available. Training on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHZ-K2Vv1qCR",
        "colab_type": "code",
        "outputId": "633c29f4-82f4-43e9-e0d1-628a3a3bfd97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# batch_size = 32\n",
        "# print('batch_size = ' + str(batch_size))\n",
        "\n",
        "# valid_size = 0.15\n",
        "\n",
        "# epoch = 15\n",
        "# print('epoch = ' + str(epoch))\n",
        "\n",
        "# random_seed = random.randint(1, 100)\n",
        "# print('random_seed = ' + str(random_seed))\n",
        "\n",
        "# shuffle = True\n",
        "# valid_loss_min = np.Inf\n",
        "# num_workers = 4\n",
        "# lossT = []\n",
        "# lossL = []\n",
        "# lossL.append(np.inf)\n",
        "# lossT.append(np.inf)\n",
        "# epoch_valid = epoch-2\n",
        "# n_iter = 1\n",
        "# i_valid = 0\n",
        "\n",
        "# pin_memory = False\n",
        "# if train_on_gpu:\n",
        "#     pin_memory = True\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_size = 32\n",
            "epoch = 15\n",
            "random_seed = 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc1P_A5lmGEu",
        "colab_type": "code",
        "outputId": "63df19ba-a1e1-4e71-a900-77afa944dac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model_Inputs = [U_Net]\n",
        "\n",
        "# def model_unet(model_input, in_channel=1, out_channel=1):\n",
        "#     model_test = model_input(in_channel, out_channel)\n",
        "#     return model_test\n",
        "\n",
        "# #passsing this string so that if it's AttU_Net or R2ATTU_Net it doesn't throw an error at torchSummary\n",
        "\n",
        "\n",
        "# model_test = model_unet(model_Inputs[0], 1, 1)\n",
        "\n",
        "# model_test.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "U_Net(\n",
              "  (Maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv1): conv_block(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Conv2): conv_block(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Conv3): conv_block(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Conv4): conv_block(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Conv5): conv_block(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up5): up_conv(\n",
              "    (up): Sequential(\n",
              "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
              "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up_conv5): conv_block(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up4): up_conv(\n",
              "    (up): Sequential(\n",
              "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
              "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up_conv4): conv_block(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up3): up_conv(\n",
              "    (up): Sequential(\n",
              "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
              "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up_conv3): conv_block(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up2): up_conv(\n",
              "    (up): Sequential(\n",
              "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
              "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Up_conv2): conv_block(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (Conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wx9SEUyJmMm",
        "colab_type": "code",
        "outputId": "e3315f24-06b5-4980-d683-7630d0f53583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# train_glob = '/content/drive/My Drive/CMPUT 617(PROJECT)/project/new train/*.dcm'\n",
        "# train_fns = sorted(glob.glob(train_glob))[600:700]\n",
        "# df_full = pd.read_csv('/content/drive/My Drive/CMPUT 617(PROJECT)/project/train-rle.csv', index_col='ImageId')\n",
        "\n",
        "# #######################################################\n",
        "# #Passing the Dataset of Images and Labels\n",
        "# #######################################################\n",
        "# im_height = 1024\n",
        "# im_width = 1024\n",
        "# im_chan = 1\n",
        "# # Get train images and masks\n",
        "# X_train = np.zeros((len(train_fns), im_height, im_width, im_chan), dtype=np.uint8)\n",
        "# Y_train = np.zeros((len(train_fns), im_height, im_width, 1), dtype=np.bool)\n",
        "# print('Getting train images and masks ... ')\n",
        "# sys.stdout.flush()\n",
        "# for n, _id in tqdm(enumerate(train_fns), total=len(train_fns)):\n",
        "#     dataset = pydicom.read_file(_id)\n",
        "#     X_train[n] = np.expand_dims(dataset.pixel_array, axis=2)\n",
        "#     try:\n",
        "#         if '-1' in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n",
        "#             Y_train[n] = np.zeros((1024, 1024, 1))\n",
        "#         else:\n",
        "#             if type(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']) == str:\n",
        "#                 Y_train[n] = np.expand_dims(rle2mask(df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels'], 1024, 1024), axis=2)\n",
        "#             else:\n",
        "#                 Y_train[n] = np.zeros((1024, 1024, 1))\n",
        "#                 for x in df_full.loc[_id.split('/')[-1][:-4],' EncodedPixels']:\n",
        "#                     Y_train[n] =  Y_train[n] + np.expand_dims(rle2mask(x, 1024, 1024), axis=2)\n",
        "#     except KeyError:\n",
        "#         print(f\"Key {_id.split('/')[-1][:-4]} without mask, assuming healthy patient.\")\n",
        "#         Y_train[n] = np.zeros((1024, 1024, 1)) # Assume missing masks are empty masks.\n",
        "\n",
        "# print('Done!')\n",
        "# np.save('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_test', X_train)\n",
        "# np.save('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_test', Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting train images and masks ... \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 54/100 [00:17<00:14,  3.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Key 1.2.276.0.7230010.3.1.4.8323329.10599.1517875224.488727 without mask, assuming healthy patient.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:32<00:00,  3.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awPf2Iv2TbPR",
        "colab_type": "code",
        "outputId": "170d5ed5-caa1-4d34-dca9-de631f98565a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# # import numpy as np\n",
        "# # from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "# # from torch import Tensor\n",
        "# # ###########################\n",
        "\n",
        "# X_train = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_train.npy')\n",
        "# Y_train = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_train.npy')\n",
        "# X_valid = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_valid.npy')\n",
        "# Y_valid = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_valid.npy')\n",
        "# im_height = 128\n",
        "# im_width = 128\n",
        "# X_train = X_train.reshape((-1, im_height, im_width, 1))\n",
        "# Y_train = Y_train.reshape((-1, im_height, im_width, 1))\n",
        "# X_valid = X_valid.reshape((-1, im_height, im_width, 1))\n",
        "# Y_valid = Y_valid.reshape((-1, im_height, im_width, 1))\n",
        "# print(np.shape(X_train))\n",
        "\n",
        "# X_train = np.transpose(X_train, (0,3,2,1))\n",
        "# Y_train =np.transpose(Y_train , (0,3,2,1))\n",
        "# X_valid =np.transpose(X_valid, (0,3,2,1))\n",
        "# Y_valid= np.transpose(Y_valid, (0,3,2,1))\n",
        "# dataset = TensorDataset( Tensor(X_train), Tensor(Y_train) )\n",
        "# dataset2 =  TensorDataset( Tensor(X_valid), Tensor(Y_valid))\n",
        "# train_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "# valid_loader = torch.utils.data.DataLoader(dataset2, batch_size=1, shuffle=True)\n",
        "# # # Normalizing the whole dataset and finding std and average\n",
        "# # # uncomment lines below to see the average and std for the whole data set\n",
        "# # ############\n",
        "# # train_loader_test = torch.utils.data.DataLoader(Tensor(X_train), batch_size=32, shuffle=True)\n",
        "# # def calculate_img_stats_avg(loader):\n",
        "# #     mean = 0.\n",
        "# #     std = 0.\n",
        "# #     nb_samples = 0.\n",
        "# #     for imgs,_ in loader:\n",
        "# #         batch_samples = imgs.size(0)\n",
        "# #         imgs = imgs.view(batch_samples, imgs.size(1), -1)\n",
        "# #         mean += imgs.mean(2).sum(0)\n",
        "# #         std += imgs.std(2).sum(0)\n",
        "# #         nb_samples += batch_samples\n",
        "\n",
        "# #     mean /= nb_samples\n",
        "# #     std /= nb_samples\n",
        "# #     return mean,std\n",
        "# # print(calculate_img_stats_avg(train_loader_test))\n",
        "# # # #################\n",
        "# initial_lr = 0.001\n",
        "# opt = torch.optim.Adam(model_test.parameters(), lr=initial_lr) # try SGD\n",
        "# #opt = optim.SGD(model_test.parameters(), lr = initial_lr, momentum=0.99)\n",
        "\n",
        "# MAX_STEP = int(1e10)\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, MAX_STEP, eta_min=1e-5)\n",
        "# ##########\n",
        "# New_folder = './model'\n",
        "# if os.path.exists(New_folder) and os.path.isdir(New_folder):\n",
        "#     shutil.rmtree(New_folder)\n",
        "\n",
        "# try:\n",
        "#     os.mkdir(New_folder)\n",
        "# except OSError:\n",
        "#     print(\"Creation of the main directory '%s' failed \" % New_folder)\n",
        "# else:\n",
        "#     print(\"Successfully created the main directory '%s' \" % New_folder)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32000, 128, 128, 1)\n",
            "Successfully created the main directory './model' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LubMOpJCkxon",
        "colab_type": "code",
        "outputId": "0143dfb7-29fd-425a-bd8b-005f91269a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# #######################################################\n",
        "# #Training loop\n",
        "# #######################################################\n",
        "# for i in range(epoch):\n",
        "\n",
        "#     train_loss = 0.0\n",
        "#     valid_loss = 0.0\n",
        "#     since = time.time()\n",
        "#     # scheduler.step(i)\n",
        "#     lr = 10**-3\n",
        "\n",
        "#     #######################################################\n",
        "#     #Training Data\n",
        "#     #######################################################\n",
        "\n",
        "#     model_test.train()\n",
        "#     k = 1\n",
        "\n",
        "#     for x, y in train_loader:\n",
        "#         x, y = x.to(device), y.to(device)\n",
        "\n",
        "#         #If want to get the input images with their Augmentation - To check the data flowing in net\n",
        "#         #input_images(x, y, i, n_iter, k)\n",
        "\n",
        "#        # grid_img = torchvision.utils.make_grid(x)\n",
        "#         #writer1.add_image('images', grid_img, 0)\n",
        "\n",
        "#        # grid_lab = torchvision.utils.make_grid(y)\n",
        "\n",
        "#         opt.zero_grad()\n",
        "#         y_pred = model_test(x)\n",
        "#         lossT = calc_loss(y_pred, y)     # Dice_loss Used\n",
        "#         train_loss += lossT.item() * x.size(0)\n",
        "#         lossT.backward()\n",
        "#       #  plot_grad_flow(model_test.named_parameters(), n_iter)\n",
        "#         opt.step()\n",
        "#         x_size = lossT.item() * x.size(0)\n",
        "#         k = 2\n",
        "\n",
        "#     #    for name, param in model_test.named_parameters():\n",
        "#     #        name = name.replace('.', '/')\n",
        "#     #        writer1.add_histogram(name, param.data.cpu().numpy(), i + 1)\n",
        "#     #        writer1.add_histogram(name + '/grad', param.grad.data.cpu().numpy(), i + 1)\n",
        "\n",
        "\n",
        "#     #######################################################\n",
        "#     #Validation Step\n",
        "#     #######################################################\n",
        "\n",
        "#     model_test.eval()\n",
        "#     torch.no_grad() #to increase the validation process uses less memory\n",
        "\n",
        "#     for x1, y1 in valid_loader:\n",
        "#         x1, y1 = x1.to(device), y1.to(device)\n",
        "\n",
        "#         y_pred1 = model_test(x1)\n",
        "#         lossL = calc_loss(y_pred1, y1)     # Dice_loss Used\n",
        "\n",
        "#         valid_loss += lossL.item() * x1.size(0)\n",
        "#         x_size1 = lossL.item() * x1.size(0)\n",
        "\n",
        "\n",
        "\n",
        "#     #######################################################\n",
        "#     #To write in Tensorboard\n",
        "#     #######################################################\n",
        "#     (train_idx) = 15\n",
        "#     valid_idx= 15\n",
        "#     train_loss = train_loss / (train_idx)\n",
        "#     valid_loss = valid_loss / (valid_idx)\n",
        "\n",
        "#     if (i+1) % 1 == 0:\n",
        "#         print('Epoch: {}/{} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(i + 1, epoch, train_loss,\n",
        "#                                                                                       valid_loss))\n",
        "\n",
        "\n",
        "# torch.save(model_test.state_dict(), '/content/drive/My Drive/CMPUT 617(PROJECT)/project/MODEL.pt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n",
            "torch.Size([1, 1, 128, 128])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-56eb01e90f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mlossT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Dice_loss Used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-186cba38eedf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0md5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0md5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUp_conv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0md4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUp4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-186cba38eedf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDvK-J95HsAv",
        "colab_type": "code",
        "outputId": "cbf8606d-302b-439e-c2ec-e738ac091e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "U_Net().load_state_dict(torch.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/MODEL.pt'))\n",
        "U_Net().eval()\n",
        "##########################\n",
        "X_test = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/X_test.npy')\n",
        "Y_test = np.load('/content/drive/My Drive/CMPUT 617(PROJECT)/project/Y_test.npy')\n",
        "print(X_test.shape)\n",
        "X_test = X_test.reshape((-1, im_height, im_width, 1))\n",
        "Y_test = Y_test.reshape((-1, im_height, im_width, 1))\n",
        "X_test = np.transpose(X_test, (0,3,2,1))\n",
        "Y_test = np.transpose(Y_test , (0,3,2,1))\n",
        "print(X_test.shape)\n",
        "dataset_test = TensorDataset( Tensor(X_test), Tensor(Y_test) )\n",
        "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=True)\n",
        "\n",
        "def accuracy(output, target):\n",
        "    \"\"\"Computes the accuracy for multiple binary predictions\"\"\"\n",
        "    pred = output >= 0.5\n",
        "    truth = target >= 0.5\n",
        "    acc = pred.eq(truth).sum() / target.numel()\n",
        "    return acc\n",
        "def dice_score(input, target):\n",
        "    eps = 1e-8\n",
        "\n",
        "    iflat = input.view(-1)\n",
        "    tflat = target.view(-1)\n",
        "    intersection = (iflat * tflat).sum()\n",
        "\n",
        "    return ((2. * intersection + eps) /\n",
        "            (iflat.sum() + tflat.sum() + eps))\n",
        "    \n",
        "\n",
        "########################################\n",
        "torch.no_grad() #to increase the validation process uses less memory\n",
        "j=1\n",
        "for x1, y1 in test_loader:\n",
        "    x1, y1 = x1.to(device), y1.to(device)\n",
        "    # # print(y1.shape)\n",
        "    # # print(y1)\n",
        "    # y_pred1 = model_test(x1)\n",
        "    # lossL = dice_coeff(y1.cpu(), y_pred1.cpu().detach().numpy(), empty_score=1.0)    # Dice_loss Used\n",
        "    j=j+1\n",
        "    plt.imshow(y1.squeeze(1).squeeze(0).detach().cpu())\n",
        "    plt.show()\n",
        "    if(j==20):\n",
        "      break     \n",
        "    \n",
        "\n",
        "    \n",
        " \n",
        "\n",
        "\n",
        "\n",
        "    #######################################################\n",
        "    #To write in Tensorboard\n",
        "    #######################################################"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1024, 1024, 1)\n",
            "(6400, 1, 128, 128)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAN90lEQVR4nO3df+xddX3H8edr/YXgtK2YprZk1Ni4\nMLMN8g0/wmII1YmMCEsIwZhZHUuzhW2oS7SMP8j+k82omGy6BtRuYSCrbDSEjWHFmP1hZ1GHQEEq\nDGlTKERAowkr870/7mFcyrdpveee+/3Oz/ORfHPP+Zxz7nn3c+995ZxzT+8nVYWkdv3SQhcgaWEZ\nAlLjDAGpcYaA1DhDQGqcISA1brAQSHJBkoeT7Euydaj9SOonQ9wnkGQJ8D3gncB+4JvAe6vqwanv\nTFIvSwd63jOBfVX1KECSW4CLgXlDYHlW1AmcNFApkgB+zLPPVNUbj2wfKgTWAU+Mze8HzhpfIckW\nYAvACZzIWdk0UCmSAL5SOx6fr33BLgxW1baqmququWWsWKgypOYNFQIHgFPG5td3bZIWmaFC4JvA\nxiQbkiwHLgd2DrQvST0Mck2gql5M8sfAXcAS4PNV9cAQ+5LUz1AXBqmqO4E7h3p+SdPhHYNS4wwB\nqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZ\nAlLjDAGpcYaA1DhDQGqcISA1zhCQGmcISI0zBKTGGQJS4yYOgSSnJLknyYNJHkhyVde+OsndSR7p\nHldNr1xJ09bnSOBF4M+q6jTgbODKJKcBW4FdVbUR2NXNS1qkJg6BqjpYVd/qpn8M7AXWARcD27vV\ntgOX9C1S0nCmMiBpklOB04HdwJqqOtgtehJYc5RttgBbAE7gxGmUIWkCvS8MJnkt8GXgQ1X1o/Fl\nVVVAzbddVW2rqrmqmlvGir5lSJpQrxBIsoxRANxUVbd1zU8lWdstXwsc6leipCH1+XYgwI3A3qr6\n5NiincDmbnozcPvk5UkaWp9rAucCvwd8N8l3urY/Bz4O3JrkCuBx4LJ+JUoa0sQhUFX/DuQoizdN\n+rySZss7BqXGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwh\nIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGqcISA1zhCQGmcISI0zBKTGTWNU4iVJvp3kjm5+\nQ5LdSfYl+VKS5f3LlDSUaRwJXAXsHZu/DvhUVb0FeBa4Ygr7kDSQvkOTrwd+B7ihmw9wPrCjW2U7\ncEmffUgaVt8jgU8DHwV+1s2/AXiuql7s5vcD6+bbMMmWJHuS7DnMCz3LkDSpiUMgyUXAoaq6d5Lt\nq2pbVc1V1dwyVkxahqSeJh6aHDgXeE+SC4ETgNcB1wMrkyztjgbWAwf6lylpKBMfCVTV1VW1vqpO\nBS4HvlpV7wPuAS7tVtsM3N67SkmDGeI+gY8BH0myj9E1ghsH2IekKelzOvB/quprwNe66UeBM6fx\nvJKG5x2DUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGqcISA1zhCQ\nGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSkxhkCUuN6hUCSlUl2JHkoyd4k\n5yRZneTuJI90j6umVayk6et7JHA98K9V9avAbwB7ga3ArqraCOzq5iUtUhOHQJLXA2+nG3C0qv67\nqp4DLga2d6ttBy7pW6Sk4fQ5EtgAPA18Icm3k9yQ5CRgTVUd7NZ5Elgz38ZJtiTZk2TPYV7oUYak\nPvqEwFLgDOCzVXU68BOOOPSvqgJqvo2raltVzVXV3DJW9ChDUh99QmA/sL+qdnfzOxiFwlNJ1gJ0\nj4f6lShpSBOHQFU9CTyR5K1d0ybgQWAnsLlr2wzc3qtCSYNa2nP7PwFuSrIceBT4IKNguTXJFcDj\nwGU99yFpQL1CoKq+A8zNs2hTn+eVNDveMSg1zhCQGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEg\nNc4QkBpnCEiNMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhD\nQGqcISA1rlcIJPlwkgeS3J/k5iQnJNmQZHeSfUm+1A1RJmmRmjgEkqwD/hSYq6q3AUuAy4HrgE9V\n1VuAZ4ErplGopGH0PR1YCrwmyVLgROAgcD6jYcoBtgOX9NyHpAH1GZr8APAJ4AeMPvzPA/cCz1XV\ni91q+4F1822fZEuSPUn2HOaFScuQ1FOf04FVwMXABuBNwEnABce7fVVtq6q5qppbxopJy5DUU5/T\ngXcAj1XV01V1GLgNOBdY2Z0eAKwHDvSsUdKA+oTAD4Czk5yYJMAm4EHgHuDSbp3NwO39SpQ0pD7X\nBHYzugD4LeC73XNtAz4GfCTJPuANwI1TqFPSQJYee5Wjq6prgWuPaH4UOLPP80qaHe8YlBpnCEiN\nMwSkxhkCUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLjDAGpcYaA1DhDQGqcISA1zhCQ\nGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBp3zBBI8vkkh5LcP9a2OsndSR7pHld17Uny\nmST7ktyX5Iwhi5fU3/EcCXyRVw85vhXYVVUbgV3dPMC7gY3d3xbgs9MpU9JQjhkCVfV14IdHNF8M\nbO+mtwOXjLX/XY18g9Ew5WunVayk6Zv0msCaqjrYTT8JrOmm1wFPjK23v2t7lSRbkuxJsucwL0xY\nhqS+el8YrKoCaoLttlXVXFXNLWNF3zIkTWjSEHjqpcP87vFQ134AOGVsvfVdm6RFatIQ2Als7qY3\nA7ePtb+/+5bgbOD5sdMGSYvQ0mOtkORm4Dzg5CT7gWuBjwO3JrkCeBy4rFv9TuBCYB/wU+CDA9Qs\naYqOGQJV9d6jLNo0z7oFXNm3KEmz4x2DUuMMAalxhoDUOENAapwhIDXOEJAaZwhIjTMEpMYZAlLj\nDAGpcYaA1DhDQGqcISA1zhCQGmcISI0zBKTGGQJS4wwBqXGGgNQ4Q0BqnCEgNc4QkBpnCEiNMwSk\nxhkCUuOOGQJJPp/kUJL7x9r+KslDSe5L8k9JVo4tuzrJviQPJ3nXUIVLmo7jORL4InDBEW13A2+r\nql8HvgdcDZDkNOBy4Ne6bf4myZKpVStp6o4ZAlX1deCHR7T9W1W92M1+g9EQ5AAXA7dU1QtV9Rij\ngUnPnGK9kqZsGtcEfh/4l256HfDE2LL9XdurJNmSZE+SPYd5YQplSJpErxBIcg3wInDTz7ttVW2r\nqrmqmlvGij5lSOrhmEOTH02SDwAXAZu6IckBDgCnjK22vmuTtEhNdCSQ5ALgo8B7quqnY4t2Apcn\nWZFkA7AR+I/+ZUoayjGPBJLcDJwHnJxkP3Ato28DVgB3JwH4RlX9YVU9kORW4EFGpwlXVtX/DFW8\npP7y8pH8wnldVtdZ2bTQZUi/0L5SO+6tqrkj271jUGqcISA1zhCQGmcISI0zBKTGGQJS4wwBqXGL\n4j6BJE8DPwGeWehagJOxjnHW8Ur/n+v4lap645GNiyIEAJLsme9GBuuwDusYtg5PB6TGGQJS4xZT\nCGxb6AI61vFK1vFKv3B1LJprApIWxmI6EpC0AAwBqXGLIgSSXNCNU7AvydYZ7fOUJPckeTDJA0mu\n6tpXJ7k7ySPd46oZ1bMkybeT3NHNb0iyu+uTLyVZPoMaVibZ0Y0psTfJOQvRH0k+3L0m9ye5OckJ\ns+qPo4yzMW8fZOQzXU33JTlj4DqGGe+jqhb0D1gCfB94M7Ac+E/gtBnsdy1wRjf9y4zGTzgN+Etg\na9e+FbhuRv3wEeAfgDu6+VuBy7vpzwF/NIMatgN/0E0vB1bOuj8Y/Tr1Y8BrxvrhA7PqD+DtwBnA\n/WNt8/YBcCGjX9oOcDawe+A6fhtY2k1fN1bHad3nZgWwofs8LTnufQ39xjqOf+w5wF1j81cDVy9A\nHbcD7wQeBtZ2bWuBh2ew7/XALuB84I7uTfXM2Av+ij4aqIbXdx++HNE+0/7g5Z+tX83o5+/uAN41\ny/4ATj3iwzdvHwB/C7x3vvWGqOOIZb8L3NRNv+IzA9wFnHO8+1kMpwPHPVbBUJKcCpwO7AbWVNXB\nbtGTwJoZlPBpRj/c+rNu/g3Ac/XyAC+z6JMNwNPAF7rTkhuSnMSM+6OqDgCfAH4AHASeB+5l9v0x\n7mh9sJDv3YnG+5jPYgiBBZXktcCXgQ9V1Y/Gl9UoVgf9DjXJRcChqrp3yP0ch6WMDj8/W1WnM/q/\nHK+4PjOj/ljFaCSrDcCbgJN49TB4C2YWfXAsfcb7mM9iCIEFG6sgyTJGAXBTVd3WNT+VZG23fC1w\naOAyzgXek+S/gFsYnRJcD6xM8tKvQc+iT/YD+6tqdze/g1EozLo/3gE8VlVPV9Vh4DZGfTTr/hh3\ntD6Y+Xt3bLyP93WB1LuOxRAC3wQ2dld/lzMa0HTn0DvN6LfSbwT2VtUnxxbtBDZ305sZXSsYTFVd\nXVXrq+pURv/2r1bV+4B7gEtnWMeTwBNJ3to1bWL00/Ez7Q9GpwFnJzmxe41eqmOm/XGEo/XBTuD9\n3bcEZwPPj502TN1g430MeZHn57gAciGjq/PfB66Z0T5/i9Fh3X3Ad7q/Cxmdj+8CHgG+AqyeYT+c\nx8vfDry5eyH3Af8IrJjB/n8T2NP1yT8DqxaiP4C/AB4C7gf+ntFV75n0B3Azo2sRhxkdHV1xtD5g\ndAH3r7v37XeBuYHr2Mfo3P+l9+vnxta/pqvjYeDdP8++vG1YatxiOB2QtIAMAalxhoDUOENAapwh\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIDXOEJAaZwhIjftfks9zwsnDO+kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}